#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys

# è®¾ç½®CUDAè®¾å¤‡
os.environ["CUDA_VISIBLE_DEVICES"] = "0"

import torch


def test_cuda():
    print("ğŸ”§ CUDA æµ‹è¯•")
    print("=" * 50)

    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    print(f"CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES', 'Not set')}")

    # æ£€æŸ¥CUDAå¯ç”¨æ€§
    print(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")

    if torch.cuda.is_available():
        print(f"GPU æ•°é‡: {torch.cuda.device_count()}")
        print(f"å½“å‰è®¾å¤‡: {torch.cuda.current_device()}")
        print(f"è®¾å¤‡åç§°: {torch.cuda.get_device_name(0)}")

        # æµ‹è¯•ç®€å•çš„CUDAæ“ä½œ
        try:
            x = torch.tensor([1.0, 2.0, 3.0]).cuda()
            y = x * 2
            print(f"CUDA æµ‹è¯•æˆåŠŸ: {y.cpu().numpy()}")
        except Exception as e:
            print(f"CUDA æ“ä½œå¤±è´¥: {e}")
    else:
        print("âŒ CUDA ä¸å¯ç”¨")
        print("å¯èƒ½çš„åŸå› :")
        print("1. NVIDIA é©±åŠ¨æœªå®‰è£…æˆ–ç‰ˆæœ¬ä¸å…¼å®¹")
        print("2. CUDA æœªå®‰è£…æˆ–ç‰ˆæœ¬ä¸å…¼å®¹")
        print("3. PyTorch ç‰ˆæœ¬ä¸æ”¯æŒ CUDA")


if __name__ == "__main__":
    test_cuda()
