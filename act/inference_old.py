# -- coding: UTF-8
"""
æœºå™¨äººæ¨ç†è„šæœ¬ - å®æ—¶æ§åˆ¶ARXåŒè‡‚æœºå™¨äºº
æœ¬è„šæœ¬å®ç°äº†å®Œæ•´çš„æœºå™¨äººæ§åˆ¶æµç¨‹ï¼šè§‚æµ‹è·å– -> æ¨¡å‹æ¨ç† -> åŠ¨ä½œæ‰§è¡Œ

ä¸»è¦åŠŸèƒ½æ¨¡å—ï¼š
1. å¤šè¿›ç¨‹æ¶æ„ï¼šROSè¿›ç¨‹è´Ÿè´£æ•°æ®é€šä¿¡ï¼Œæ¨ç†è¿›ç¨‹è´Ÿè´£æ¨¡å‹é¢„æµ‹
2. å…±äº«å†…å­˜æœºåˆ¶ï¼šå®ç°è¿›ç¨‹é—´é«˜æ•ˆæ•°æ®ä¼ é€’
3. å®æ—¶è§‚æµ‹è·å–ï¼šä»æ‘„åƒå¤´å’Œå…³èŠ‚çŠ¶æ€ä¼ æ„Ÿå™¨è·å–æ•°æ®
4. ç¥ç»ç½‘ç»œæ¨ç†ï¼šä½¿ç”¨è®­ç»ƒå¥½çš„ACT/CNN/Diffusionæ¨¡å‹é¢„æµ‹åŠ¨ä½œ
5. åŠ¨ä½œæ‰§è¡Œï¼šå°†é¢„æµ‹çš„åŠ¨ä½œå‘é€ç»™æœºå™¨äººæ‰§è¡Œ
"""

import os
import sys

# è®¾ç½®æ ‡å‡†è¾“å‡ºå’Œæ ‡å‡†é”™è¯¯çš„ç¼“å†²æ¨¡å¼ä¸ºè¡Œç¼“å†²ï¼Œç¡®ä¿å®æ—¶è¾“å‡º
sys.stdout = open(sys.stdout.fileno(), mode="w", buffering=1)
sys.stderr = open(sys.stderr.fileno(), mode="w", buffering=1)

from pathlib import Path

# è®¾ç½®é¡¹ç›®æ ¹è·¯å¾„ï¼Œç¡®ä¿æ¨¡å—å¯¼å…¥æ­£ç¡®
FILE = Path(__file__).resolve()
ROOT = FILE.parents[0]
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))
    os.chdir(str(ROOT))

import argparse
import collections
import pickle
import yaml
from einops import rearrange
import rclpy
import torch
import threading

from rclpy.executors import MultiThreadedExecutor

# å¯¼å…¥ç­–ç•¥æ¨¡å‹ï¼ˆACTã€CNN-MLPã€Diffusion Policyï¼‰
from utils.policy import ACTPolicy, CNNMLPPolicy, DiffusionPolicy
from utils.utils import set_seed  # éšæœºç§å­è®¾ç½®

# å¯¼å…¥ROSæ“ä½œç±»å’Œå…¶ä»–å·¥å…·
from utils.ros_operator import RosOperator, Rate
from utils.setup_loader import setup_loader
from functools import partial
import signal
import sys

# å…¨å±€è§‚æµ‹å­—å…¸ï¼Œç”¨äºå­˜å‚¨å½“å‰è§‚æµ‹æ•°æ®
obs_dict = collections.OrderedDict()

import multiprocessing as mp
from multiprocessing.shared_memory import SharedMemory

import numpy as np

# è®¾ç½®numpyè¾“å‡ºæ ¼å¼ï¼Œæ–¹ä¾¿è°ƒè¯•
np.set_printoptions(linewidth=200)  # è®¾ç½®æ‰“å°è¾“å‡ºè¡Œå®½
np.set_printoptions(suppress=True)  # ç¦ç”¨ç§‘å­¦è®¡æ•°æ³•


def load_yaml(yaml_file):
    """
    åŠ è½½YAMLé…ç½®æ–‡ä»¶

    Args:
        yaml_file (str): YAMLæ–‡ä»¶è·¯å¾„

    Returns:
        dict: è§£æåçš„é…ç½®å­—å…¸ï¼Œå‡ºé”™æ—¶è¿”å›None
    """
    try:
        with open(yaml_file, "r", encoding="utf-8") as file:
            return yaml.safe_load(file)
    except FileNotFoundError:
        print(f"Error: File not found - {yaml_file}")

        return None
    except yaml.YAMLError as e:
        print(f"Error: Failed to parse YAML file - {e}")

        return None


def make_shm_name_dict(args, shapes):
    """
    åˆ›å»ºå…±äº«å†…å­˜åç§°å­—å…¸
    ä¸ºæ¯ä¸ªæ•°æ®ç±»å‹ï¼ˆå›¾åƒã€çŠ¶æ€ã€åŠ¨ä½œï¼‰åˆ†é…å”¯ä¸€çš„å…±äº«å†…å­˜åç§°

    Args:
        args: å‘½ä»¤è¡Œå‚æ•°ï¼ŒåŒ…å«æ‘„åƒå¤´åç§°ç­‰
        shapes: æ•°æ®å½¢çŠ¶å­—å…¸

    Returns:
        dict: å…±äº«å†…å­˜åç§°æ˜ å°„å­—å…¸
    """
    shm_name_dict = {}
    # ä¸ºæ¯ä¸ªæ‘„åƒå¤´åˆ›å»ºå…±äº«å†…å­˜åç§°
    for cam in args.camera_names:
        shm_name_dict[cam] = f"shm_img_{cam}"
    # ä¸ºæ¯ä¸ªçŠ¶æ€å˜é‡åˆ›å»ºå…±äº«å†…å­˜åç§°
    for state_key in shapes["states"]:
        shm_name_dict[state_key] = f"shm_state_{state_key}"
    # ä¸ºåŠ¨ä½œåˆ›å»ºå…±äº«å†…å­˜åç§°
    shm_name_dict["action"] = "shm_action"

    return shm_name_dict


def create_shm_dict(config, shm_name_dict, shapes, dtypes):
    """
    åˆ›å»ºå…±äº«å†…å­˜å­—å…¸
    ä¸ºå›¾åƒæ•°æ®ã€çŠ¶æ€æ•°æ®å’ŒåŠ¨ä½œæ•°æ®åˆ†é…å…±äº«å†…å­˜ç©ºé—´

    Args:
        config: æ¨¡å‹é…ç½®
        shm_name_dict: å…±äº«å†…å­˜åç§°å­—å…¸
        shapes: æ•°æ®å½¢çŠ¶å­—å…¸
        dtypes: æ•°æ®ç±»å‹å­—å…¸

    Returns:
        dict: å…±äº«å†…å­˜å¯¹è±¡å­—å…¸ï¼Œæ¯ä¸ªæ¡ç›®åŒ…å«(SharedMemoryå¯¹è±¡, å½¢çŠ¶, æ•°æ®ç±»å‹)
    """
    shm_dict = {}

    # ä¸ºå›¾åƒæ•°æ®åˆ›å»ºå…±äº«å†…å­˜
    for cam, shape in shapes["images"].items():
        size = np.prod(shape) * np.dtype(dtypes[cam]).itemsize
        shm = SharedMemory(name=shm_name_dict[cam], create=True, size=size)
        shm_dict[cam] = (shm, shape, dtypes[cam])

    # ä¸ºçŠ¶æ€æ•°æ®åˆ›å»ºå…±äº«å†…å­˜
    for state_key, shape in shapes["states"].items():
        size = np.prod(shape) * np.dtype(np.float32).itemsize
        shm = SharedMemory(name=shm_name_dict[state_key], create=True, size=size)
        shm_dict[state_key] = (shm, shape, np.float32)

    # ä¸ºåŠ¨ä½œæ•°æ®åˆ›å»ºå…±äº«å†…å­˜
    action_shape = config["policy_config"]["action_dim"]
    size = np.prod(action_shape) * np.dtype(np.float32).itemsize
    shm = SharedMemory(name=shm_name_dict["action"], create=True, size=size)
    shm_dict["action"] = (shm, action_shape, np.float32)

    return shm_dict


def connect_shm_dict(shm_name_dict, shapes, dtypes, config):
    """
    è¿æ¥åˆ°å·²å­˜åœ¨çš„å…±äº«å†…å­˜
    æ¨ç†è¿›ç¨‹ä½¿ç”¨æ­¤å‡½æ•°è¿æ¥åˆ°ROSè¿›ç¨‹åˆ›å»ºçš„å…±äº«å†…å­˜

    Args:
        shm_name_dict: å…±äº«å†…å­˜åç§°å­—å…¸
        shapes: æ•°æ®å½¢çŠ¶å­—å…¸
        dtypes: æ•°æ®ç±»å‹å­—å…¸
        config: æ¨¡å‹é…ç½®

    Returns:
        dict: å…±äº«å†…å­˜å¯¹è±¡å­—å…¸
    """
    shm_dict = {}

    # è¿æ¥å›¾åƒå…±äº«å†…å­˜
    for cam, shape in shapes["images"].items():
        shm = SharedMemory(name=shm_name_dict[cam], create=False)
        shm_dict[cam] = (shm, shape, dtypes[cam])

    # è¿æ¥çŠ¶æ€å…±äº«å†…å­˜
    for state_key, shape in shapes["states"].items():
        shm = SharedMemory(name=shm_name_dict[state_key], create=False)
        shm_dict[state_key] = (shm, shape, np.float32)

    # è¿æ¥åŠ¨ä½œå…±äº«å†…å­˜
    action_shape = (config["policy_config"]["action_dim"],)
    shm = SharedMemory(name=shm_name_dict["action"], create=False)
    shm_dict["action"] = (shm, action_shape, np.float32)

    return shm_dict


def robot_action(action, shm_dict):
    """
    å°†åŠ¨ä½œå†™å…¥å…±äº«å†…å­˜
    æ¨ç†è¿›ç¨‹ä½¿ç”¨æ­¤å‡½æ•°å°†é¢„æµ‹çš„åŠ¨ä½œä¼ é€’ç»™ROSè¿›ç¨‹æ‰§è¡Œ

    Args:
        action: é¢„æµ‹çš„åŠ¨ä½œæ•°ç»„
        shm_dict: å…±äº«å†…å­˜å­—å…¸
    """
    shm, shape, dtype = shm_dict["action"]
    np_array = np.ndarray(shape, dtype=dtype, buffer=shm.buf)
    np_array[:] = action


def get_model_config(args):
    """
    é…ç½®æ¨¡å‹å‚æ•°
    æ ¹æ®å‘½ä»¤è¡Œå‚æ•°åˆ›å»ºå®Œæ•´çš„æ¨¡å‹é…ç½®å­—å…¸

    Args:
        args: è§£æåçš„å‘½ä»¤è¡Œå‚æ•°

    Returns:
        dict: åŒ…å«æ¨¡å‹ã€è®­ç»ƒã€æ¨ç†æ‰€éœ€çš„å®Œæ•´é…ç½®
    """
    set_seed(args.seed)

    # åŸºç¡€é…ç½®ï¼Œæ‰€æœ‰ç­–ç•¥éƒ½ä¼šä½¿ç”¨
    base_config = {
        "lr": args.lr,
        "lr_backbone": args.lr_backbone,
        "weight_decay": args.weight_decay,
        "loss_function": args.loss_function,
        "backbone": args.backbone,
        "chunk_size": args.chunk_size,
        "hidden_dim": args.hidden_dim,
        "camera_names": args.camera_names,
        "position_embedding": args.position_embedding,
        "masks": args.masks,
        "dilation": args.dilation,
        "use_base": args.use_base,
        "use_depth_image": args.use_depth_image,
    }

    # æ ¹æ®ç­–ç•¥ç±»å‹é…ç½®ç‰¹å®šå‚æ•°
    if args.policy_class == "ACT":
        # ACTï¼ˆAction Chunking with Transformersï¼‰ç­–ç•¥é…ç½®
        policy_config = {
            **base_config,
            "enc_layers": args.enc_layers,  # ç¼–ç å™¨å±‚æ•°
            "dec_layers": args.dec_layers,  # è§£ç å™¨å±‚æ•°
            "nheads": args.nheads,  # æ³¨æ„åŠ›å¤´æ•°
            "dropout": args.dropout,  # Dropoutç‡
            "pre_norm": args.pre_norm,  # é¢„å½’ä¸€åŒ–
            "states_dim": 7,  # åŸºç¡€çŠ¶æ€ç»´åº¦ï¼ˆå•è‡‚7ä¸ªå…³èŠ‚ï¼‰
            "action_dim": 7,  # åŸºç¡€åŠ¨ä½œç»´åº¦ï¼ˆå•è‡‚7ä¸ªå…³èŠ‚ï¼‰
            "kl_weight": args.kl_weight,  # KLæ•£åº¦æƒé‡
            "dim_feedforward": args.dim_feedforward,  # å‰é¦ˆç½‘ç»œç»´åº¦
            "use_qvel": args.use_qvel,  # æ˜¯å¦ä½¿ç”¨å…³èŠ‚é€Ÿåº¦
            "use_effort": args.use_effort,  # æ˜¯å¦ä½¿ç”¨å…³èŠ‚åŠ›çŸ©
            "use_eef_states": args.use_eef_states,  # æ˜¯å¦ä½¿ç”¨æœ«ç«¯æ‰§è¡Œå™¨çŠ¶æ€
        }

        # åŠ¨æ€æ›´æ–°çŠ¶æ€ç»´åº¦
        policy_config["states_dim"] += (
            policy_config["action_dim"] if args.use_qvel else 0
        )
        policy_config["states_dim"] += 1 if args.use_effort else 0
        policy_config["states_dim"] *= 2  # åŒè‡‚ç³»ç»Ÿ

        # åŠ¨æ€æ›´æ–°åŠ¨ä½œç»´åº¦
        policy_config["action_dim"] *= 2  # åŒè‡‚é¢„æµ‹ï¼ˆå·¦è‡‚+å³è‡‚ï¼‰
        policy_config["action_dim"] += 10 if args.use_base else 0  # ç§»åŠ¨åº•ç›˜
        policy_config["action_dim"] *= 2  # å†æ¬¡ä¹˜2ï¼ˆå¯èƒ½ç”¨äºä¸åŒçš„åŠ¨ä½œè¡¨ç¤ºï¼‰

        action_dim = policy_config["action_dim"]
        states_dim = policy_config["states_dim"]
        print(f"{action_dim=}", f"{states_dim=}")

    elif args.policy_class == "CNNMLP":
        # CNN-MLPç­–ç•¥é…ç½®ï¼ˆç®€å•çš„å·ç§¯+å¤šå±‚æ„ŸçŸ¥æœºï¼‰
        policy_config = {
            **base_config,
            "action_dim": 14,  # å›ºå®š14ç»´åŠ¨ä½œ
            "states_dim": 14,  # å›ºå®š14ç»´çŠ¶æ€
        }
    elif args.policy_class == "Diffusion":
        # æ‰©æ•£æ¨¡å‹ç­–ç•¥é…ç½®
        policy_config = {
            **base_config,
            "observation_horizon": args.observation_horizon,  # è§‚æµ‹å†å²é•¿åº¦
            "action_horizon": args.action_horizon,  # åŠ¨ä½œé¢„æµ‹é•¿åº¦
            "num_inference_timesteps": args.num_inference_timesteps,  # æ¨ç†æ—¶é—´æ­¥æ•°
            "ema_power": args.ema_power,  # æŒ‡æ•°ç§»åŠ¨å¹³å‡åŠŸç‡
            "action_dim": 14,
            "states_dim": 14,
        }
    else:
        raise NotImplementedError

    # å®Œæ•´çš„é…ç½®å­—å…¸
    config = {
        "ckpt_dir": (
            args.ckpt_dir if sys.stdin.isatty() else Path.joinpath(ROOT, args.ckpt_dir)
        ),
        "ckpt_name": args.ckpt_name,  # æ¨¡å‹æƒé‡æ–‡ä»¶å
        "ckpt_stats_name": args.ckpt_stats_name,  # æ•°æ®ç»Ÿè®¡æ–‡ä»¶å
        "episode_len": args.max_publish_step,  # å•å›åˆæœ€å¤§æ­¥æ•°
        "state_dim": policy_config["states_dim"],
        "policy_class": args.policy_class,
        "policy_config": policy_config,
        "temporal_agg": args.temporal_agg,  # æ—¶åºèšåˆ
        "camera_names": args.camera_names,
    }

    return config


def make_policy(policy_class, policy_config):
    """
    åˆ›å»ºç­–ç•¥æ¨¡å‹å®ä¾‹

    Args:
        policy_class: ç­–ç•¥ç±»å‹ ('ACT', 'CNNMLP', 'Diffusion')
        policy_config: ç­–ç•¥é…ç½®å­—å…¸

    Returns:
        ç­–ç•¥æ¨¡å‹å¯¹è±¡
    """
    if policy_class == "ACT":
        policy = ACTPolicy(policy_config)
    elif policy_class == "CNNMLP":
        policy = CNNMLPPolicy(policy_config)
    elif policy_class == "Diffusion":
        policy = DiffusionPolicy(policy_config)
    else:
        raise NotImplementedError

    return policy


def get_image(observation, camera_names):
    """
    å¤„ç†å›¾åƒè§‚æµ‹æ•°æ®
    å°†å¤šä¸ªæ‘„åƒå¤´çš„å›¾åƒæ•°æ®è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼

    Args:
        observation: è§‚æµ‹æ•°æ®å­—å…¸
        camera_names: æ‘„åƒå¤´åç§°åˆ—è¡¨

    Returns:
        torch.Tensor: å½’ä¸€åŒ–åçš„å›¾åƒå¼ é‡ [1, C*N, H, W]
                     C=3ä¸ºRGBé€šé“æ•°ï¼ŒNä¸ºæ‘„åƒå¤´æ•°é‡
    """
    curr_images = []
    for cam_name in camera_names:
        # å°†å›¾åƒä» (H, W, C) è½¬æ¢ä¸º (C, H, W) æ ¼å¼
        curr_image = rearrange(observation["images"][cam_name], "h w c -> c h w")
        curr_images.append(curr_image)

    # å †å æ‰€æœ‰æ‘„åƒå¤´å›¾åƒï¼š[N, C, H, W]
    curr_image = np.stack(curr_images, axis=0)
    # å½’ä¸€åŒ–åˆ°[0,1]å¹¶è½¬æ¢ä¸ºGPUå¼ é‡ï¼Œæ·»åŠ batchç»´åº¦ï¼š[1, N*C, H, W]
    curr_image = torch.from_numpy(curr_image / 255.0).float().cuda().unsqueeze(0)

    return curr_image


def get_depth_image(observation, camera_names):
    """
    å¤„ç†æ·±åº¦å›¾åƒè§‚æµ‹æ•°æ®

    Args:
        observation: è§‚æµ‹æ•°æ®å­—å…¸
        camera_names: æ‘„åƒå¤´åç§°åˆ—è¡¨

    Returns:
        torch.Tensor: æ·±åº¦å›¾åƒå¼ é‡
    """
    curr_images = []
    for cam_name in camera_names:
        curr_images.append(observation["images_depth"][cam_name])
    curr_image = np.stack(curr_images, axis=0)
    curr_image = torch.from_numpy(curr_image / 255.0).float().cuda().unsqueeze(0)

    return curr_image


def apply_gripper_gate(action_value, gate):
    """
    åº”ç”¨å¤¹çˆªé˜ˆå€¼æ§åˆ¶
    å°†è¿ç»­çš„å¤¹çˆªåŠ¨ä½œå€¼è½¬æ¢ä¸ºç¦»æ•£çš„å¼€/å…³çŠ¶æ€

    Args:
        action_value: åŸå§‹åŠ¨ä½œå€¼
        gate: é˜ˆå€¼

    Returns:
        int: ç¦»æ•£åŒ–åçš„å¤¹çˆªåŠ¨ä½œ (0=å…³é—­, 5=æ‰“å¼€)
    """
    min_gripper = 0
    max_gripper = 5

    return min_gripper if action_value < gate else max_gripper


def get_obervations(args, timestep, ros_operator):
    """
    è·å–å•æ¬¡è§‚æµ‹æ•°æ®
    ä»ROSç³»ç»Ÿè·å–å½“å‰æ—¶åˆ»çš„ä¼ æ„Ÿå™¨æ•°æ®

    Args:
        args: å‘½ä»¤è¡Œå‚æ•°
        timestep: å½“å‰æ—¶é—´æ­¥
        ros_operator: ROSæ“ä½œå¯¹è±¡

    Returns:
        dict: è§‚æµ‹æ•°æ®å­—å…¸ï¼ŒåŒ…å«å›¾åƒå’ŒçŠ¶æ€ä¿¡æ¯
    """
    global obs_dict

    rate = Rate(args.frame_rate)  # è®¾ç½®å¾ªç¯é¢‘ç‡
    while True and rclpy.ok():
        # å°è¯•è·å–åŒæ­¥çš„è§‚æµ‹æ•°æ®
        obs_dict = ros_operator.get_observation(ts=timestep)
        if not obs_dict:
            print("syn fail")  # åŒæ­¥å¤±è´¥
            rate.sleep()
            continue

        return obs_dict


def init_robot(ros_operator, use_base, connected_event, start_event):
    """
    æœºå™¨äººåˆå§‹åŒ–å‡½æ•°
    å°†æœºå™¨äººç§»åŠ¨åˆ°å®‰å…¨çš„åˆå§‹ä½ç½®ï¼Œå‡†å¤‡å¼€å§‹ä»»åŠ¡æ‰§è¡Œ

    Args:
        ros_operator: ROSæ“ä½œå¯¹è±¡
        use_base: æ˜¯å¦ä½¿ç”¨ç§»åŠ¨åº•ç›˜
        connected_event: è¿æ¥å®Œæˆäº‹ä»¶
        start_event: å¼€å§‹ä»»åŠ¡äº‹ä»¶
    """
    # é¢„å®šä¹‰çš„å®‰å…¨åˆå§‹ä½ç½®ï¼ˆå…³èŠ‚è§’åº¦ï¼‰
    init0 = [0.0, 0.948, 0.858, -0.573, 0.0, 0.0, -2.8]  # å¤¹çˆªæ‰“å¼€çŠ¶æ€
    init1 = [0.0, 0.948, 0.858, -0.573, 0.0, 0.0, 0.0]  # å¤¹çˆªå…³é—­çŠ¶æ€

    # å‘å¸ƒåˆå§‹ä½ç½®ï¼ˆå…³èŠ‚ç©ºé—´å§¿æ€ï¼‰- åŒè‡‚åŒæ—¶ç§»åŠ¨åˆ°åˆå§‹ä½ç½®
    ros_operator.follow_arm_publish_continuous(init0, init0)

    # é€šçŸ¥ä¸»è¿›ç¨‹æœºå™¨äººå·²è¿æ¥å¹¶åˆå§‹åŒ–å®Œæˆ
    connected_event.set()
    # ç­‰å¾…ä¸»è¿›ç¨‹ç¡®è®¤å¼€å§‹ä»»åŠ¡
    start_event.wait()

    # å°†å¤¹çˆªè®¾ç½®ä¸ºå…³é—­çŠ¶æ€ï¼Œå‡†å¤‡æ“ä½œ
    ros_operator.follow_arm_publish_continuous(init1, init1)
    if use_base:
        # å¦‚æœä½¿ç”¨åº•ç›˜ï¼Œå¯åŠ¨åº•ç›˜æ§åˆ¶çº¿ç¨‹
        ros_operator.start_base_control_thread()


def signal_handler(signal, frame, ros_operator):
    """
    ä¿¡å·å¤„ç†å‡½æ•°ï¼Œå¤„ç†Ctrl+Cä¸­æ–­
    å®‰å…¨å…³é—­æœºå™¨äººæ§åˆ¶

    Args:
        signal: ä¿¡å·ç±»å‹
        frame: å †æ ˆå¸§
        ros_operator: ROSæ“ä½œå¯¹è±¡
    """
    print("Caught Ctrl+C / SIGINT signal")

    # å®‰å…¨å…³é—­åº•ç›˜æ§åˆ¶
    ros_operator.base_enable = False
    ros_operator.robot_base_shutdown()
    ros_operator.base_control_thread.join()

    sys.exit(0)


def cleanup_shm(names):
    """
    æ¸…ç†å…±äº«å†…å­˜
    åˆ é™¤å¯èƒ½æ®‹ç•™çš„å…±äº«å†…å­˜å¯¹è±¡

    Args:
        names: å…±äº«å†…å­˜åç§°åˆ—è¡¨
    """
    for name in names:
        try:
            shm = SharedMemory(name=name)
            shm.close()
            shm.unlink()
        except FileNotFoundError:
            pass  # å…±äº«å†…å­˜ä¸å­˜åœ¨ï¼Œå¿½ç•¥é”™è¯¯


def ros_process(
    args, config, meta_queue, connected_event, start_event, shm_ready_event
):
    """
    ROSè¿›ç¨‹ä¸»å‡½æ•° - è§‚æµ‹è·å–å’ŒåŠ¨ä½œæ‰§è¡Œ
    è¿™æ˜¯ç³»ç»Ÿçš„æ ¸å¿ƒè¿›ç¨‹ï¼Œè´Ÿè´£ï¼š
    1. åˆå§‹åŒ–ROSç³»ç»Ÿå’Œæœºå™¨äºº
    2. å»ºç«‹å…±äº«å†…å­˜é€šä¿¡
    3. å®æ—¶è·å–ä¼ æ„Ÿå™¨è§‚æµ‹æ•°æ®
    4. æ‰§è¡Œæ¨¡å‹é¢„æµ‹çš„åŠ¨ä½œ

    Args:
        args: å‘½ä»¤è¡Œå‚æ•°
        config: æ¨¡å‹é…ç½®
        meta_queue: å…ƒæ•°æ®é˜Ÿåˆ—ï¼Œç”¨äºè¿›ç¨‹é—´é€šä¿¡
        connected_event: è¿æ¥äº‹ä»¶ï¼Œé€šçŸ¥æœºå™¨äººåˆå§‹åŒ–å®Œæˆ
        start_event: å¼€å§‹äº‹ä»¶ï¼Œå…è®¸ä»»åŠ¡å¼€å§‹æ‰§è¡Œ
        shm_ready_event: å…±äº«å†…å­˜å°±ç»ªäº‹ä»¶
    """

    def _ros_spin(executor):
        """ROSäº‹ä»¶å¾ªç¯å‡½æ•°"""
        executor.spin()

    # åŠ è½½ROSç¯å¢ƒå’Œä¾èµ–
    setup_loader(ROOT)

    # åˆå§‹åŒ–ROS2ç³»ç»Ÿ
    rclpy.init()

    # åŠ è½½æœºå™¨äººé…ç½®æ–‡ä»¶
    data = load_yaml(args.data)
    ros_operator = RosOperator(args, data, in_collect=False)  # æ¨ç†æ¨¡å¼

    # åˆ›å»ºå¤šçº¿ç¨‹æ‰§è¡Œå™¨ï¼Œå¤„ç†ROSå›è°ƒ
    executor = MultiThreadedExecutor()
    executor.add_node(ros_operator)

    # åœ¨åå°çº¿ç¨‹ä¸­è¿è¡ŒROSäº‹ä»¶å¾ªç¯
    spin_thread = threading.Thread(target=_ros_spin, args=(executor,), daemon=True)
    spin_thread.start()

    # è®¾ç½®ä¿¡å·å¤„ç†ï¼ˆç”¨äºå®‰å…¨å…³é—­åº•ç›˜ï¼‰
    if args.use_base:
        signal.signal(signal.SIGINT, partial(signal_handler, ros_operator=ros_operator))

    # åˆå§‹åŒ–æœºå™¨äººåˆ°å®‰å…¨ä½ç½®
    init_robot(ros_operator, args.use_base, connected_event, start_event)

    # === é˜¶æ®µ1ï¼šè·å–æ•°æ®å½¢çŠ¶ä¿¡æ¯ ===
    rate = Rate(args.frame_rate)
    while rclpy.ok():
        # è·å–ä¸€æ¬¡è§‚æµ‹æ•°æ®æ¥ç¡®å®šæ•°æ®å½¢çŠ¶
        obs = ros_operator.get_observation()
        if obs:
            # æ„å»ºæ•°æ®å½¢çŠ¶å­—å…¸ï¼Œç”¨äºåˆ›å»ºå…±äº«å†…å­˜
            shapes = {"images": {}, "states": {}, "dtypes": {}}

            # è®°å½•æ¯ä¸ªæ‘„åƒå¤´å›¾åƒçš„å½¢çŠ¶å’Œæ•°æ®ç±»å‹
            for cam in args.camera_names:
                img = obs["images"][cam]
                shapes["images"][cam] = img.shape
                shapes["dtypes"][cam] = img.dtype

            # è®°å½•æœºå™¨äººçŠ¶æ€æ•°æ®çš„å½¢çŠ¶
            shapes["states"]["qpos"] = obs["qpos"].shape  # å…³èŠ‚ä½ç½®
            shapes["states"]["qvel"] = obs["qvel"].shape  # å…³èŠ‚é€Ÿåº¦
            shapes["states"]["effort"] = obs["effort"].shape  # å…³èŠ‚åŠ›çŸ©
            shapes["states"]["robot_base"] = obs["robot_base"].shape  # åº•ç›˜çŠ¶æ€
            shapes["states"]["base_velocity"] = obs["base_velocity"].shape  # åº•ç›˜é€Ÿåº¦

            # å°†å½¢çŠ¶ä¿¡æ¯å‘é€ç»™ä¸»è¿›ç¨‹
            meta_queue.put(shapes)
            break

        rate.sleep()

    # === é˜¶æ®µ2ï¼šå»ºç«‹å…±äº«å†…å­˜é€šä¿¡ ===
    # ä»ä¸»è¿›ç¨‹æ¥æ”¶å…±äº«å†…å­˜åç§°å­—å…¸
    shm_name_dict = meta_queue.get()

    # æ¸…ç†å¯èƒ½æ®‹ç•™çš„å…±äº«å†…å­˜
    cleanup_shm(shm_name_dict.values())
    # åˆ›å»ºæ–°çš„å…±äº«å†…å­˜ç©ºé—´
    shm_dict = create_shm_dict(config, shm_name_dict, shapes, shapes["dtypes"])
    # é€šçŸ¥ä¸»è¿›ç¨‹å…±äº«å†…å­˜å·²å°±ç»ª
    shm_ready_event.set()

    # === é˜¶æ®µ3ï¼šä¸»å¾ªç¯ - è§‚æµ‹è·å–å’ŒåŠ¨ä½œæ‰§è¡Œ ===
    rate = Rate(args.frame_rate)
    while rclpy.ok():
        # 1. è·å–æœ€æ–°è§‚æµ‹æ•°æ®
        obs = ros_operator.get_observation()
        if not obs:
            rate.sleep()
            continue

        # 2. å°†è§‚æµ‹æ•°æ®å†™å…¥å…±äº«å†…å­˜ï¼ˆä¾›æ¨ç†è¿›ç¨‹ä½¿ç”¨ï¼‰
        # å†™å…¥å›¾åƒæ•°æ®
        for cam in args.camera_names:
            shm, shape, dtype = shm_dict[cam]
            np_array = np.ndarray(shape, dtype=dtype, buffer=shm.buf)
            np_array[:] = obs["images"][cam]

        # å†™å…¥çŠ¶æ€æ•°æ®
        for state_key in shapes["states"]:
            shm, shape, dtype = shm_dict[state_key]
            np_array = np.ndarray(shape, dtype=dtype, buffer=shm.buf)
            np_array[:] = obs[state_key]

        # 3. ä»å…±äº«å†…å­˜è¯»å–åŠ¨ä½œå¹¶æ‰§è¡Œ
        shm, shape, dtype = shm_dict["action"]
        action = np.ndarray(shape, dtype=dtype, buffer=shm.buf).copy()

        if np.any(action):  # ç¡®ä¿åŠ¨ä½œä¸å…¨æ˜¯0ï¼ˆå³æœ‰æœ‰æ•ˆçš„é¢„æµ‹åŠ¨ä½œï¼‰
            gripper_gate = args.gripper_gate

            # åŠ¨ä½œåˆ†è§£ï¼šåŒè‡‚ç³»ç»Ÿçš„å…³èŠ‚ç´¢å¼•
            gripper_idx = [6, 13]  # å·¦è‡‚å¤¹çˆªç´¢å¼•6ï¼Œå³è‡‚å¤¹çˆªç´¢å¼•13

            # æå–å·¦è‡‚åŠ¨ä½œï¼ˆå‰7ä¸ªå…³èŠ‚ï¼š6ä¸ªè‡ªç”±åº¦+å¤¹çˆªï¼‰
            left_action = action[: gripper_idx[0] + 1]
            if gripper_gate != -1:
                # åº”ç”¨å¤¹çˆªé˜ˆå€¼æ§åˆ¶
                left_action[gripper_idx[0]] = apply_gripper_gate(
                    left_action[gripper_idx[0]], gripper_gate
                )

            # æå–å³è‡‚åŠ¨ä½œï¼ˆå…³èŠ‚7-13ï¼š6ä¸ªè‡ªç”±åº¦+å¤¹çˆªï¼‰
            right_action = action[gripper_idx[0] + 1 : gripper_idx[1] + 1]
            if gripper_gate != -1:
                # æ³¨æ„ï¼šè¿™é‡Œå¯èƒ½æ˜¯åŸä»£ç çš„é”™è¯¯ï¼Œåº”è¯¥æ˜¯right_action[gripper_idx[0]]
                right_action[gripper_idx[0]] = apply_gripper_gate(
                    left_action[gripper_idx[0]], gripper_gate
                )

            # å‘å¸ƒåŒè‡‚åŠ¨ä½œåˆ°æœºå™¨äºº
            ros_operator.follow_arm_publish(left_action, right_action)

            # å¦‚æœå¯ç”¨åº•ç›˜ï¼Œæå–å¹¶å‘å¸ƒåº•ç›˜åŠ¨ä½œ
            if args.use_base:
                action_base = action[
                    gripper_idx[1] + 1 : gripper_idx[1] + 1 + 10
                ]  # 10ç»´åº•ç›˜åŠ¨ä½œ
                ros_operator.set_robot_base_target(action_base)

        rate.sleep()

    # æ¸…ç†èµ„æº
    executor.shutdown()
    rclpy.shutdown()
    for shm, _, _ in shm_dict.values():
        shm.close()
        shm.unlink()


def inference_process(args, config, shm_dict, shapes, ros_proc):
    model = make_policy(config["policy_class"], config["policy_config"])
    ckpt_dir = (
        config["ckpt_dir"]
        if sys.stdin.isatty()
        else Path.joinpath(ROOT, config["ckpt_dir"])
    )
    ckpt_path = os.path.join(ckpt_dir, config["ckpt_name"])
    loading_status = model.load_state_dict(torch.load(ckpt_path, weights_only=True))
    print(loading_status)

    # åŠ è½½ç»Ÿè®¡ä¿¡æ¯
    stats_path = os.path.join(config["ckpt_dir"], config["ckpt_stats_name"])
    with open(stats_path, "rb") as f:
        stats = pickle.load(f)

    chunk_size = config["policy_config"]["chunk_size"]
    hidden_dim = config["policy_config"]["hidden_dim"]
    action_dim = config["policy_config"]["action_dim"]

    use_qvel = config["policy_config"]["use_qvel"]
    use_effort = config["policy_config"]["use_effort"]
    use_eef_states = config["policy_config"]["use_eef_states"]

    use_robot_base = config["policy_config"]["use_base"]
    action = np.zeros((action_dim,))

    pre_left_states_process = (
        lambda s: (s - stats["left_states_mean"]) / stats["left_states_std"]
    )
    pre_right_states_process = (
        lambda s: (s - stats["right_states_mean"]) / stats["right_states_std"]
    )
    pre_robot_base_process = (
        lambda s: (s - stats["robot_base_mean"]) / stats["robot_base_std"]
    )
    pre_robot_head_process = (
        lambda s: (s - stats["robot_head_mean"]) / stats["robot_head_std"]
    )
    pre_base_velocity_process = (
        lambda s: (s - stats["base_velocity_mean"]) / stats["base_velocity_std"]
    )
    post_process = lambda a: a * stats["action_std"] + stats["action_mean"]

    model.cuda()
    model.eval()

    max_publish_step = config["episode_len"]

    # while ros_proc.is_alive():
    if config["temporal_agg"]:
        print(f"{config['state_dim']=}")

        # è®¡ç®—å†…å­˜éœ€æ±‚
        memory_gb = (
            max_publish_step
            * (max_publish_step + chunk_size)
            * action_dim
            * 8
            / (1024**3)
        )
        print(f"ğŸ“Š temporal_aggæ¨¡å¼å†…å­˜éœ€æ±‚: {memory_gb:.2f} GB")
        print(
            f"   æ•°ç»„å½¢çŠ¶: ({max_publish_step}, {max_publish_step + chunk_size}, {action_dim})"
        )

        if memory_gb > 8:
            print(f"âš ï¸  è­¦å‘Šï¼šå†…å­˜éœ€æ±‚è¾ƒå¤§({memory_gb:.2f}GB)ï¼Œè¯·ç¡®ä¿ç³»ç»Ÿæœ‰è¶³å¤Ÿå†…å­˜")

        all_time_actions = np.zeros(
            (max_publish_step, max_publish_step + chunk_size, action_dim)
        )
        print(f"âœ… åŠ¨ä½œå†å²æ•°ç»„å·²åˆ›å»º")

    timestep = 0

    with torch.inference_mode():
        print(f"ğŸš€ å¼€å§‹æ¨ç†å¾ªç¯ï¼Œæœ€å¤§æ­¥æ•°: {args.max_publish_step}")
        print(f"ğŸ“¡ ROSè¿›ç¨‹çŠ¶æ€: {'alive' if ros_proc.is_alive() else 'dead'}")

        while timestep < args.max_publish_step and ros_proc.is_alive():
            if timestep % 100 == 0:  # æ¯100æ­¥æ‰“å°ä¸€æ¬¡çŠ¶æ€
                print(f"â±ï¸  æ¨ç†æ­¥æ•°: {timestep}/{args.max_publish_step}")
            obs_dict = {
                "images": {},
                "qpos": None,
                "qvel": None,
                "effort": None,
                "robot_base": None,
                "base_velocity": None,
            }

            # ä»å…±äº«å†…å­˜è¯»å–
            try:
                for cam in args.camera_names:
                    shm, shape, dtype = shm_dict[cam]
                    obs_dict["images"][cam] = np.ndarray(
                        shape, dtype=dtype, buffer=shm.buf
                    ).copy()
                for state_key in shapes["states"]:
                    shm, shape, dtype = shm_dict[state_key]
                    obs_dict[state_key] = np.ndarray(
                        shape, dtype=dtype, buffer=shm.buf
                    ).copy()
            except Exception as e:
                print(f"âŒ å…±äº«å†…å­˜è¯»å–é”™è¯¯: {e}")
                print(f"   æ­¥æ•°: {timestep}")
                break

            gripper_idx = [6, 13]

            left_qpos = (
                obs_dict["eef"][: gripper_idx[0] + 1]
                if use_eef_states
                else obs_dict["qpos"][: gripper_idx[0] + 1]
            )
            left_states = left_qpos

            right_qpos = (
                obs_dict["eef"][gripper_idx[0] + 1 : gripper_idx[1] + 1]
                if use_eef_states
                else obs_dict["qpos"][gripper_idx[0] + 1 : gripper_idx[1] + 1]
            )
            right_states = right_qpos

            left_states = (
                np.concatenate(
                    (left_states, obs_dict["qvel"][: gripper_idx[0] + 1]), axis=0
                )
                if use_qvel
                else left_states
            )
            left_states = (
                np.concatenate(
                    (
                        left_states,
                        obs_dict["effort"][gripper_idx[0] : gripper_idx[0] + 1],
                    ),
                    axis=0,
                )
                if use_effort
                else left_states
            )

            right_states = (
                np.concatenate(
                    (
                        right_states,
                        obs_dict["qvel"][gripper_idx[0] + 1 : gripper_idx[1] + 1],
                    ),
                    axis=0,
                )
                if use_qvel
                else right_states
            )  #
            right_states = (
                np.concatenate(
                    (
                        right_states,
                        obs_dict["effort"][gripper_idx[1] : gripper_idx[1] + 1],
                    ),
                    axis=0,
                )
                if use_effort
                else right_states
            )  #

            left_states = np.concatenate((left_states, right_states), axis=0)
            right_states = left_states

            robot_base = obs_dict["robot_base"][:3]

            robot_base = pre_robot_base_process(robot_base)
            robot_base = torch.from_numpy(robot_base).float().cuda().unsqueeze(0)

            robot_head = obs_dict["robot_base"][3:6]
            robot_head = pre_robot_head_process(robot_head)
            robot_head = torch.from_numpy(robot_head).float().cuda().unsqueeze(0)

            base_velocity = obs_dict["base_velocity"]
            base_velocity = pre_base_velocity_process(base_velocity)
            base_velocity = torch.from_numpy(base_velocity).float().cuda().unsqueeze(0)

            left_states = pre_left_states_process(left_states)
            left_states = torch.from_numpy(left_states).float().cuda().unsqueeze(0)

            right_states = pre_right_states_process(right_states)
            right_states = torch.from_numpy(right_states).float().cuda().unsqueeze(0)

            curr_image = get_image(obs_dict, config["camera_names"])
            curr_depth_image = None

            if args.use_depth_image:
                curr_depth_image = get_depth_image(obs_dict, config["camera_names"])

            if config["policy_class"] == "ACT":
                # ===== æ­¥éª¤1: æ¨¡å‹æ¨ç† =====
                # å°†å½“å‰è§‚æµ‹æ•°æ®è¾“å…¥ACTæ¨¡å‹ï¼Œè·å–æœªæ¥chunk_sizeæ­¥çš„åŠ¨ä½œé¢„æµ‹
                # all_actionså½¢çŠ¶: (1, chunk_size, action_dim)
                # ä¾‹å¦‚: (1, 30, 14) è¡¨ç¤ºé¢„æµ‹æœªæ¥30æ­¥çš„14ç»´åŠ¨ä½œ
                try:
                    if timestep % 100 == 0:
                        print(f"ğŸ§  å¼€å§‹æ¨¡å‹æ¨ç†ï¼Œæ­¥æ•°: {timestep}")
                    all_actions = model(
                        curr_image,  # å½“å‰å›¾åƒè§‚æµ‹ [1, C*N, H, W]
                        curr_depth_image,  # å½“å‰æ·±åº¦å›¾åƒ [1, C*N, H, W] (å¯é€‰)
                        left_states,  # å·¦è‡‚çŠ¶æ€ [1, states_dim]
                        right_states,  # å³è‡‚çŠ¶æ€ [1, states_dim]
                        robot_base=robot_base,  # æœºå™¨äººåº•ç›˜ä½ç½® [1, 3]
                        robot_head=robot_head,  # æœºå™¨äººå¤´éƒ¨å§¿æ€ [1, 3]
                        base_velocity=base_velocity,  # åº•ç›˜é€Ÿåº¦ [1, 4]
                    )
                    if timestep % 100 == 0:
                        print(f"âœ… æ¨¡å‹æ¨ç†å®Œæˆï¼ŒåŠ¨ä½œå½¢çŠ¶: {all_actions.shape}")
                except Exception as e:
                    print(f"âŒ æ¨¡å‹æ¨ç†é”™è¯¯: {e}")
                    print(f"   æ­¥æ•°: {timestep}")
                    break

                # ===== æ­¥éª¤2: åŠ¨ä½œå¤„ç†åˆ†æ”¯ =====
                if config["temporal_agg"]:
                    # ===== åˆ†æ”¯A: æ—¶åºèšåˆæ¨¡å¼ =====
                    # ç”¨äºæé«˜åŠ¨ä½œçš„å¹³æ»‘æ€§å’Œç¨³å®šæ€§

                    # 2.1 å­˜å‚¨å†å²åŠ¨ä½œé¢„æµ‹
                    # å°†å½“å‰æ—¶é—´æ­¥çš„åŠ¨ä½œé¢„æµ‹å­˜å‚¨åˆ°å…¨å±€åŠ¨ä½œçŸ©é˜µä¸­
                    # all_time_actionså½¢çŠ¶: (max_publish_step, max_publish_step + chunk_size, action_dim)
                    # ä¾‹å¦‚: (10000, 10030, 14) ç”¨äºå­˜å‚¨æ‰€æœ‰æ—¶é—´æ­¥çš„åŠ¨ä½œé¢„æµ‹
                    all_time_actions[[timestep], timestep : timestep + chunk_size] = (
                        all_actions.cpu().numpy()  # è½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶å­˜å‚¨
                    )

                    # 2.2 æå–å½“å‰æ—¶é—´æ­¥çš„æ‰€æœ‰å†å²é¢„æµ‹
                    # ä»æ‰€æœ‰å†å²é¢„æµ‹ä¸­æå–å½“å‰æ—¶é—´æ­¥çš„åŠ¨ä½œ
                    # å½¢çŠ¶: (timestep+1, action_dim) - åŒ…å«ä»å¼€å§‹åˆ°å½“å‰çš„æ‰€æœ‰é¢„æµ‹
                    actions_for_curr_step = all_time_actions[:, timestep]

                    # 2.3 è¿‡æ»¤æœ‰æ•ˆé¢„æµ‹
                    # åªä¿ç•™éé›¶çš„åŠ¨ä½œé¢„æµ‹ï¼ˆæ’é™¤æœªåˆå§‹åŒ–çš„éƒ¨åˆ†ï¼‰
                    # actions_populated: å¸ƒå°”æ•°ç»„ï¼Œæ ‡è®°å“ªäº›æ—¶é—´æ­¥æœ‰æœ‰æ•ˆé¢„æµ‹
                    actions_populated = np.all(actions_for_curr_step != 0, axis=1)
                    actions_for_curr_step = actions_for_curr_step[actions_populated]

                    # 2.4 è®¡ç®—æŒ‡æ•°è¡°å‡æƒé‡
                    # ä½¿ç”¨æŒ‡æ•°è¡°å‡å‡½æ•°ç»™ä¸åŒæ—¶é—´æ­¥çš„é¢„æµ‹åˆ†é…æƒé‡
                    # è¶Šè¿‘æœŸçš„é¢„æµ‹æƒé‡è¶Šå¤§ï¼Œè¶Šæ—©æœŸçš„é¢„æµ‹æƒé‡è¶Šå°
                    k = 0.01  # è¡°å‡ç³»æ•°ï¼Œæ§åˆ¶æƒé‡è¡°å‡é€Ÿåº¦
                    exp_weights = np.exp(-k * np.arange(len(actions_for_curr_step)))
                    exp_weights = exp_weights / exp_weights.sum()  # å½’ä¸€åŒ–æƒé‡
                    exp_weights = exp_weights[:, np.newaxis]  # æ·»åŠ ç»´åº¦ç”¨äºå¹¿æ’­

                    # 2.5 åŠ æƒå¹³å‡è®¡ç®—æœ€ç»ˆåŠ¨ä½œ
                    # å°†å†å²é¢„æµ‹æŒ‰æƒé‡è¿›è¡ŒåŠ æƒå¹³å‡ï¼Œå¾—åˆ°å¹³æ»‘çš„æœ€ç»ˆåŠ¨ä½œ
                    # å½¢çŠ¶: (1, action_dim)
                    raw_action = (actions_for_curr_step * exp_weights).sum(
                        axis=0, keepdims=True
                    )
                else:
                    # ===== åˆ†æ”¯B: ç›´æ¥æ¨¡å¼ =====
                    # ä¸ä½¿ç”¨æ—¶åºèšåˆï¼Œç›´æ¥ä½¿ç”¨å½“å‰é¢„æµ‹çš„åŠ¨ä½œ

                    if args.pos_lookahead_step != 0:
                        # 2.1 ä½ç½®å‰ç»æ¨¡å¼
                        # ä½¿ç”¨ç‰¹å®šçš„å‰ç»æ­¥æ•°æ¥é€‰æ‹©åŠ¨ä½œ
                        # ç”¨äºå¤„ç†ä½ç½®ç›¸å…³çš„ç‰¹æ®Šæ§åˆ¶éœ€æ±‚
                        raw_action = all_actions[
                            :, timestep % args.model.inference.pos_lookahead_step
                        ]
                    else:
                        # 2.2 æ ‡å‡†æ¨¡å¼
                        # ä½¿ç”¨å½“å‰æ—¶é—´æ­¥åœ¨chunkä¸­çš„ä½ç½®æ¥é€‰æ‹©åŠ¨ä½œ
                        # timestep % chunk_size ç¡®ä¿åœ¨chunkèŒƒå›´å†…å¾ªç¯
                        raw_action = all_actions[:, timestep % chunk_size]

            else:
                # å…¶ä»–ç­–ç•¥ç±»å‹æš‚æœªå®ç°
                raise NotImplementedError

            # ===== æ­¥éª¤3: åŠ¨ä½œåå¤„ç† =====
            # å°†æ¨¡å‹è¾“å‡ºçš„åŸå§‹åŠ¨ä½œè½¬æ¢ä¸ºå®é™…å¯æ‰§è¡Œçš„åŠ¨ä½œ
            # post_processå‡½æ•°ä¼šè¿›è¡Œåå½’ä¸€åŒ–ç­‰æ“ä½œ
            # raw_action[0] å»é™¤batchç»´åº¦ï¼Œå¾—åˆ° (action_dim,) çš„åŠ¨ä½œå‘é‡
            action = post_process(raw_action[0])

            # ===== æ­¥éª¤4: åŠ¨ä½œæ‰§è¡Œ =====
            # å°†å¤„ç†åçš„åŠ¨ä½œå†™å…¥å…±äº«å†…å­˜ï¼Œä¾›ROSè¿›ç¨‹è¯»å–å¹¶æ‰§è¡Œ
            robot_action(action, shm_dict)

            # ===== æ­¥éª¤5: æ—¶é—´æ­¥æ›´æ–° =====
            timestep += 1

        # ===== æ­¥éª¤6: åº•ç›˜åŠ¨ä½œæ¸…ç† =====
        # å¦‚æœä½¿ç”¨ç§»åŠ¨åº•ç›˜ï¼Œåœ¨æ¨ç†ç»“æŸæ—¶å°†æŸäº›åº•ç›˜åŠ¨ä½œè®¾ä¸º0
        # è¿™å¯èƒ½æ˜¯ä¸ºäº†å®‰å…¨åœæ­¢æˆ–é‡ç½®æŸäº›åº•ç›˜åŠŸèƒ½
        if args.use_base:
            action[16] = 0  # åº•ç›˜åŠ¨ä½œç´¢å¼•16è®¾ä¸º0
            action[17] = 0  # åº•ç›˜åŠ¨ä½œç´¢å¼•17è®¾ä¸º0
            action[19] = 0  # åº•ç›˜åŠ¨ä½œç´¢å¼•19è®¾ä¸º0

        # ===== æ­¥éª¤7: æœ€ç»ˆåŠ¨ä½œæ‰§è¡Œ =====
        # æ‰§è¡Œæ¸…ç†åçš„æœ€ç»ˆåŠ¨ä½œ
        robot_action(action, shm_dict)


def parse_args(known=False):
    parser = argparse.ArgumentParser()  # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser.add_argument(
        "--max_publish_step", type=int, default=3600, help="max publish step"
    )  # å•å›åˆæœ€å¤§æ­¥æ•°ï¼Œé»˜è®¤3600æ­¥åŒ¹é…æ•°æ®é›†é•¿åº¦

    # æ•°æ®é›†å’Œæ£€æŸ¥ç‚¹è®¾ç½®
    parser.add_argument(
        "--ckpt_dir", type=str, default=Path.joinpath(ROOT, "weights"), help="ckpt dir"
    )
    parser.add_argument(
        "--ckpt_name", type=str, default="policy_best.ckpt", help="ckpt name"
    )
    parser.add_argument("--pretrain_ckpt", type=str, default="", help="pretrain ckpt")
    parser.add_argument(
        "--ckpt_stats_name",
        type=str,
        default="dataset_stats.pkl",
        help="ckpt stats name",
    )

    # é…ç½®æ–‡ä»¶
    parser.add_argument(
        "--data",
        type=str,
        default=Path.joinpath(ROOT, "data/config.yaml"),
        help="config file",
    )

    # æ¨ç†è®¾ç½®
    parser.add_argument("--seed", type=int, default=0, help="seed")
    parser.add_argument("--lr", type=float, default=1e-5, help="learning rate")
    parser.add_argument(
        "--lr_backbone", type=float, default=1e-5, help="learning rate for backbone"
    )
    parser.add_argument(
        "--weight_decay", type=float, default=1e-4, help="weight decay rate"
    )
    parser.add_argument(
        "--loss_function",
        type=str,
        choices=["l1", "l2", "l1+l2"],
        default="l1",
        help="loss function",
    )
    parser.add_argument(
        "--pos_lookahead_step", type=int, default=0, help="position lookahead step"
    )

    # æ¨¡å‹ç»“æ„è®¾ç½®
    parser.add_argument(
        "--policy_class",
        type=str,
        choices=["CNNMLP", "ACT", "Diffusion"],
        default="ACT",
        help="policy class selection",
    )
    parser.add_argument(
        "--backbone", type=str, default="resnet18", help="backbone model architecture"
    )
    parser.add_argument(
        "--chunk_size", type=int, default=30, help="chunk size for input data"
    )
    parser.add_argument(
        "--hidden_dim", type=int, default=512, help="hidden layer dimension size"
    )

    # æ‘„åƒå¤´å’Œä½ç½®åµŒå…¥è®¾ç½®
    parser.add_argument(
        "--camera_names",
        nargs="+",
        type=str,
        choices=[
            "head",
            "left_wrist",
            "right_wrist",
        ],
        default=["head", "left_wrist", "right_wrist"],
        help="camera names to use",
    )
    parser.add_argument(
        "--position_embedding",
        type=str,
        choices=("sine", "learned"),
        default="sine",
        help="type of positional embedding to use",
    )
    parser.add_argument(
        "--masks", action="store_true", help="train segmentation head if provided"
    )
    parser.add_argument(
        "--dilation",
        action="store_true",
        help="replace stride with dilation in the last convolutional block (DC5)",
    )

    # æœºå™¨äººè®¾ç½®
    parser.add_argument("--use_base", action="store_true", help="use robot base")
    parser.add_argument(
        "--record",
        choices=["Distance", "Speed"],
        default="Distance",
        help="record data",
    )
    parser.add_argument("--frame_rate", type=int, default=60, help="frame rate")

    # ACTæ¨¡å‹ä¸“ç”¨è®¾ç½®
    parser.add_argument(
        "--enc_layers", type=int, default=4, help="number of encoder layers"
    )
    parser.add_argument(
        "--dec_layers", type=int, default=7, help="number of decoder layers"
    )
    parser.add_argument(
        "--nheads", type=int, default=8, help="number of attention heads"
    )
    parser.add_argument(
        "--dropout", type=float, default=0.1, help="dropout rate in transformer layers"
    )
    parser.add_argument(
        "--pre_norm", action="store_true", help="use pre-normalization in transformer"
    )
    parser.add_argument(
        "--states_dim", type=int, default=14, help="state dimension size"
    )
    parser.add_argument(
        "--kl_weight", type=int, default=10, help="KL divergence weight"
    )
    parser.add_argument(
        "--dim_feedforward",
        type=int,
        default=3200,
        help="feedforward network dimension",
    )
    parser.add_argument(
        "--temporal_agg",
        type=bool,
        default=True,
        help="use temporal aggregation (uses more memory)",
    )

    # Diffusionæ¨¡å‹ä¸“ç”¨è®¾ç½®
    parser.add_argument(
        "--observation_horizon", type=int, default=1, help="observation horizon length"
    )
    parser.add_argument(
        "--action_horizon", type=int, default=8, help="action horizon length"
    )
    parser.add_argument(
        "--num_inference_timesteps",
        type=int,
        default=10,
        help="number of inference timesteps",
    )
    parser.add_argument(
        "--ema_power", type=int, default=0.75, help="EMA power for diffusion process"
    )

    # å›¾åƒè®¾ç½®
    parser.add_argument(
        "--use_depth_image", action="store_true", help="use depth image"
    )

    # çŠ¶æ€å’ŒåŠ¨ä½œè®¾ç½®
    parser.add_argument(
        "--use_qvel", action="store_true", help="include qvel in state information"
    )
    parser.add_argument(
        "--use_effort", action="store_true", help="include effort data in state"
    )
    parser.add_argument(
        "--use_eef_states", action="store_true", help="use eef data in state"
    )

    parser.add_argument(
        "--gripper_gate", type=float, default=-1, help="gripper gate threshold"
    )

    return parser.parse_known_args()[0] if known else parser.parse_args()


def main(args):
    """
    1ã€å¤šçº¿ç¨‹é€šä¿¡æœºåˆ¶ï¼šé˜Ÿåˆ—ç”¨äºæ•°æ®äº¤æ¢ï¼Œäº‹ä»¶ç”¨äºåŒæ­¥
    2ã€ROSè¿›ç¨‹+æ¨ç†è¿›ç¨‹ï¼šROSè¿›ç¨‹è´Ÿè´£æ•°æ®é€šä¿¡ï¼Œæ¨ç†è¿›ç¨‹è´Ÿè´£æ¨¡å‹é¢„æµ‹
    3ã€å…±äº«å†…å­˜æœºåˆ¶ï¼šå®ç°è¿›ç¨‹é—´é«˜æ•ˆæ•°æ®ä¼ é€’
    """
    meta_queue = mp.Queue()  # ç”¨äºåœ¨ä¸»è¿›ç¨‹å’Œæ¨ç†è¿›ç¨‹ä¹‹é—´ä¼ é€’metaä¿¡æ¯

    connected_event = mp.Event()  # ç”¨äºåœ¨ä¸»è¿›ç¨‹å’Œæ¨ç†è¿›ç¨‹ä¹‹é—´ä¼ é€’è¿æ¥äº‹ä»¶
    start_event = mp.Event()  # ç”¨äºåœ¨ä¸»è¿›ç¨‹å’Œæ¨ç†è¿›ç¨‹ä¹‹é—´ä¼ é€’å¯åŠ¨äº‹ä»¶
    shm_ready_event = mp.Event()  # ç”¨äºåœ¨ä¸»è¿›ç¨‹å’Œæ¨ç†è¿›ç¨‹ä¹‹é—´ä¼ é€’å…±äº«å†…å­˜å°±ç»ªäº‹ä»¶

    # è·å–æ¨¡å‹config
    config = get_model_config(args)

    # *å¯åŠ¨ROSè¿›ç¨‹
    ros_proc = mp.Process(
        target=ros_process,
        args=(args, config, meta_queue, connected_event, start_event, shm_ready_event),
    )
    ros_proc.start()

    connected_event.wait()
    print("ğŸš€ ç³»ç»Ÿå·²å°±ç»ªï¼Œ3ç§’åè‡ªåŠ¨å¼€å§‹æ¨ç†...")
    import time

    time.sleep(3)
    start_event.set()

    # ç­‰å¾…metaä¿¡æ¯
    shapes = meta_queue.get()

    shm_name_dict = make_shm_name_dict(args, shapes)

    meta_queue.put(shm_name_dict)

    shm_ready_event.wait()

    shm_dict = connect_shm_dict(shm_name_dict, shapes, shapes["dtypes"], config)

    # æ¨ç†
    try:
        inference_process(args, config, shm_dict, shapes, ros_proc)
    except KeyboardInterrupt:
        pass
    finally:
        for shm, _, _ in shm_dict.values():
            shm.close()
            shm.unlink()
        ros_proc.terminate()
        ros_proc.join()


if __name__ == "__main__":
    args = parse_args()
    main(args)
